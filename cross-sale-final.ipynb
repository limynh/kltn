{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# # This Python 3 environment comes with many helpful analytics libraries installed\n# # It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# # For example, here's several helpful packages to load\n\n# import numpy as np # linear algebra\n# import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# # Input data files are available in the read-only \"../input/\" directory\n# # For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\n# import os\n\n# zip_files = []\n# file_names = []\n# for dirname, _, filenames in os.walk('/kaggle/input'):\n#     for filename in filenames:\n#         print(os.path.join(dirname, filename))\n#         zip_files.append(os.path.join(dirname, filename))\n#         file_names.append(filename.replace('.zip', ''))\n\n# # You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# # You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-04-27T10:01:10.329106Z","iopub.execute_input":"2023-04-27T10:01:10.330766Z","iopub.status.idle":"2023-04-27T10:01:10.360654Z","shell.execute_reply.started":"2023-04-27T10:01:10.330708Z","shell.execute_reply":"2023-04-27T10:01:10.359559Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"# !mkdir /dataset\n# from zipfile import ZipFile\n# import pandas as pd\n\n# for file, name in zip(zip_files, file_names):\n#     if '.zip' in file:\n#         zip_file = ZipFile(file)\n#         df = pd.read_csv(zip_file.open(f'{name}'))\n#         df.to_csv(f'/dataset/{name}', index=False)\n\n# !ls /dataset","metadata":{"execution":{"iopub.status.busy":"2023-04-27T10:01:10.362799Z","iopub.execute_input":"2023-04-27T10:01:10.363637Z","iopub.status.idle":"2023-04-27T10:01:10.370932Z","shell.execute_reply.started":"2023-04-27T10:01:10.363579Z","shell.execute_reply":"2023-04-27T10:01:10.368570Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":"# Read dataset","metadata":{}},{"cell_type":"code","source":"# order_products_prior = pd.read_csv('/dataset/order_products__prior.csv')\n# aisles = pd.read_csv('/dataset/aisles.csv')\n# products = pd.read_csv('/dataset/products.csv')\n# departments = pd.read_csv('/dataset/departments.csv')","metadata":{"execution":{"iopub.status.busy":"2023-04-27T10:01:10.389054Z","iopub.execute_input":"2023-04-27T10:01:10.389633Z","iopub.status.idle":"2023-04-27T10:01:10.395872Z","shell.execute_reply.started":"2023-04-27T10:01:10.389583Z","shell.execute_reply":"2023-04-27T10:01:10.394428Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"# order_products_prior","metadata":{"execution":{"iopub.status.busy":"2023-04-27T10:01:10.398795Z","iopub.execute_input":"2023-04-27T10:01:10.399671Z","iopub.status.idle":"2023-04-27T10:01:10.407120Z","shell.execute_reply.started":"2023-04-27T10:01:10.399586Z","shell.execute_reply":"2023-04-27T10:01:10.405763Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"# order_id = order_products_prior['order_id'].unique()\n# len(order_id)\n\n\n# import numpy as np\n# order_id = np.random.choice(order_id,50000)\n# order_products_prior = order_products_prior[np.isin(order_products_prior.order_id, order_id)]\n# order_products_prior","metadata":{"execution":{"iopub.status.busy":"2023-04-27T10:01:10.409052Z","iopub.execute_input":"2023-04-27T10:01:10.410000Z","iopub.status.idle":"2023-04-27T10:01:10.419435Z","shell.execute_reply.started":"2023-04-27T10:01:10.409942Z","shell.execute_reply":"2023-04-27T10:01:10.418033Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"# num_product = products.product_id.nunique()\n# print(num_product)\n# products","metadata":{"execution":{"iopub.status.busy":"2023-04-27T10:01:10.422574Z","iopub.execute_input":"2023-04-27T10:01:10.425379Z","iopub.status.idle":"2023-04-27T10:01:10.435239Z","shell.execute_reply.started":"2023-04-27T10:01:10.425310Z","shell.execute_reply":"2023-04-27T10:01:10.433495Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"# num_aisle = aisles.aisle_id.nunique()\n# print(num_aisle)\n# aisles","metadata":{"execution":{"iopub.status.busy":"2023-04-27T10:01:10.437604Z","iopub.execute_input":"2023-04-27T10:01:10.438705Z","iopub.status.idle":"2023-04-27T10:01:10.450242Z","shell.execute_reply.started":"2023-04-27T10:01:10.438643Z","shell.execute_reply":"2023-04-27T10:01:10.447331Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"# num_depart = departments.department_id.nunique()\n# print(num_depart)\n# departments","metadata":{"execution":{"iopub.status.busy":"2023-04-27T10:01:10.453926Z","iopub.execute_input":"2023-04-27T10:01:10.454571Z","iopub.status.idle":"2023-04-27T10:01:10.465762Z","shell.execute_reply.started":"2023-04-27T10:01:10.454492Z","shell.execute_reply":"2023-04-27T10:01:10.463868Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"# porder_products_prior = order_products_prior.merge(products, on='product_id')\n# orders = porder_products_prior.groupby('order_id')\n# orders.ngroups","metadata":{"execution":{"iopub.status.busy":"2023-04-27T10:01:10.468132Z","iopub.execute_input":"2023-04-27T10:01:10.468586Z","iopub.status.idle":"2023-04-27T10:01:10.478846Z","shell.execute_reply.started":"2023-04-27T10:01:10.468544Z","shell.execute_reply":"2023-04-27T10:01:10.477367Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"# from tqdm.notebook import tqdm\n# orders = porder_products_prior.groupby('order_id')\n# process = tqdm(desc='Filtering data....', total = len(orders))\n# def filter_group(group):\n#     # lọc đi những:\n#         # tất cả sp đến từ 1 aisle_id hoặc department_id:\n#         # có số lượng department_id = 1\n#         # có số lượng aisle_id = 1\n#         # có số lượng product <5\n#     process.update(1)\n#     return group.department_id.nunique()>1 and group.aisle_id.nunique()>1  and group.product_id.nunique()>5\n\n# orders = orders.filter(filter_group)\n# orders = orders[['order_id', 'product_id', 'aisle_id', 'department_id']]\n# orders","metadata":{"execution":{"iopub.status.busy":"2023-04-27T10:01:10.481402Z","iopub.execute_input":"2023-04-27T10:01:10.482326Z","iopub.status.idle":"2023-04-27T10:01:10.493577Z","shell.execute_reply.started":"2023-04-27T10:01:10.482258Z","shell.execute_reply":"2023-04-27T10:01:10.492069Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"# orders.to_csv('/dataset/samples_filtered_44k_orders.csv', index=False)\n# orders = orders.groupby('order_id')","metadata":{"execution":{"iopub.status.busy":"2023-04-27T10:01:10.509103Z","iopub.execute_input":"2023-04-27T10:01:10.509851Z","iopub.status.idle":"2023-04-27T10:01:10.515145Z","shell.execute_reply.started":"2023-04-27T10:01:10.509800Z","shell.execute_reply":"2023-04-27T10:01:10.513377Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"# from copy import copy\n# import numpy as np\n# from tqdm.notebook import tqdm\n\n# process = tqdm(desc='Creating X-Y data....', total=len(orders))\n# num_sample = tqdm(desc='Number of sample ')\n\n\n# def to_order(group):\n#     rs = []\n#     for aisle_id in group.aisle_id.unique().tolist():\n#         Ys = group[group.aisle_id==aisle_id]\n#         Xs = group[group.aisle_id!=aisle_id]\n#         x_product_ids = Xs.product_id.tolist()\n#         x_aisle_ids = Xs.aisle_id.tolist()\n#         x_department_ids = Xs.department_id.tolist()\n#         rs.append({\n#             'x-product_ids':x_product_ids,\n#             'x-aisle_ids':x_aisle_ids,\n#             'x-department_ids': x_department_ids,\n#             'y-aisle_id':aisle_id,\n#         })\n#         num_sample.update(1)\n#     process.update(1)\n#     return rs\n\n# # apply the function to each group and combine the results\n# results = orders.apply(to_order).explode().tolist()\n# len(results)","metadata":{"execution":{"iopub.status.busy":"2023-04-27T10:01:10.526686Z","iopub.execute_input":"2023-04-27T10:01:10.527448Z","iopub.status.idle":"2023-04-27T10:01:10.532693Z","shell.execute_reply.started":"2023-04-27T10:01:10.527405Z","shell.execute_reply":"2023-04-27T10:01:10.531563Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"# import pickle\n\n# with open('train.pck', 'wb+') as f:\n#     pickle.dump((num_product, num_aisle, num_depart, results), f)\n\n# (num_product, num_aisle, num_depart)","metadata":{"execution":{"iopub.status.busy":"2023-04-27T10:01:10.567197Z","iopub.execute_input":"2023-04-27T10:01:10.568499Z","iopub.status.idle":"2023-04-27T10:01:10.573233Z","shell.execute_reply.started":"2023-04-27T10:01:10.568433Z","shell.execute_reply":"2023-04-27T10:01:10.572171Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"# import json \n# with open('sample-train-400k.json', 'w+') as f:\n#     json.dump(results, f, indent=2)","metadata":{"execution":{"iopub.status.busy":"2023-04-27T10:01:10.627158Z","iopub.execute_input":"2023-04-27T10:01:10.627604Z","iopub.status.idle":"2023-04-27T10:01:10.633773Z","shell.execute_reply.started":"2023-04-27T10:01:10.627564Z","shell.execute_reply":"2023-04-27T10:01:10.631928Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"markdown","source":"# Create training data","metadata":{}},{"cell_type":"code","source":"import pickle\nimport os\n\nif os.path.isfile('/kaggle/input/train-600k/train.pck'):\n    with open('/kaggle/input/train-600k/train.pck', 'rb') as f:\n        (num_product, num_aisle, num_depart, results) = pickle.load(f)\nelse:\n    with open('train.pck', 'rb') as f:\n        (num_product, num_aisle, num_depart, results) = pickle.load(f)\n\n(num_product, num_aisle, num_depart)","metadata":{"execution":{"iopub.status.busy":"2023-04-27T10:01:10.636872Z","iopub.execute_input":"2023-04-27T10:01:10.637371Z","iopub.status.idle":"2023-04-27T10:01:14.052401Z","shell.execute_reply.started":"2023-04-27T10:01:10.637330Z","shell.execute_reply":"2023-04-27T10:01:14.051211Z"},"trusted":true},"execution_count":15,"outputs":[{"execution_count":15,"output_type":"execute_result","data":{"text/plain":"(49688, 134, 21)"},"metadata":{}}]},{"cell_type":"code","source":"import random\n\nrandom.shuffle(results)\n\nresults = results[:35000]\n\nlen(results)","metadata":{"execution":{"iopub.status.busy":"2023-04-27T10:01:14.055495Z","iopub.execute_input":"2023-04-27T10:01:14.055914Z","iopub.status.idle":"2023-04-27T10:01:14.886187Z","shell.execute_reply.started":"2023-04-27T10:01:14.055877Z","shell.execute_reply":"2023-04-27T10:01:14.884351Z"},"trusted":true},"execution_count":16,"outputs":[{"execution_count":16,"output_type":"execute_result","data":{"text/plain":"35000"},"metadata":{}}]},{"cell_type":"code","source":"from tqdm.notebook import tqdm\nimport numpy as np\nfrom scipy.sparse import csr_matrix\n\n\nX = []\nX_aisle_only = []\ny_aisle_label = []\nfor idx, basket in tqdm(enumerate(results)):\n    x_product_id = np.array([0,]* (num_product))\n    x_aisle_id =  np.array([0,] * (num_aisle))\n    unique, counts = np.unique(basket['x-product_ids'], return_counts=True)\n    x_product_id[unique-1] = counts\n    \n    unique, counts = np.unique(basket['x-aisle_ids'], return_counts=True)    \n    x_aisle_id[unique-1] = counts\n    X_aisle_only.append(x_aisle_id)\n    x = np.concatenate((x_product_id, x_aisle_id), axis=0)\n    X.append(x)\n    y_aisle_label.append(basket['y-aisle_id']) \n\nX = np.stack(X, axis=0)\nX = csr_matrix(X)\nX_aisle_only = np.stack(X_aisle_only, axis=0)\ny = np.array(y_aisle_label) -1 # convert index to starting from 0\nX.shape, y.shape","metadata":{"execution":{"iopub.status.busy":"2023-04-27T10:01:14.889579Z","iopub.execute_input":"2023-04-27T10:01:14.891086Z","iopub.status.idle":"2023-04-27T10:04:20.377040Z","shell.execute_reply.started":"2023-04-27T10:01:14.891023Z","shell.execute_reply":"2023-04-27T10:04:20.375228Z"},"trusted":true},"execution_count":17,"outputs":[{"output_type":"display_data","data":{"text/plain":"0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7963e7209e0d49d9a4f0165563cb2e04"}},"metadata":{}},{"execution_count":17,"output_type":"execute_result","data":{"text/plain":"((35000, 49822), (35000,))"},"metadata":{}}]},{"cell_type":"markdown","source":"# Comprarative models\n___\n## Preprocessing techs:\n<!-- * Do nothing (dense vector) -->\n<!-- * Chi2 feature engineering -->\n* Aisle_id only\n* Product_id + Aisle_id -> TruncatedSVD 1000 (Halko, et al. (2009). “Finding structure with randomness: Stochastic algorithms for constructing approximate matrix decompositions”)\n<!-- * PCA (Implements the probabilistic PCA model from: Tipping, M. E., and Bishop, C. M. (1999). “Probabilistic principal component analysis”. Journal of the Royal Statistical Society: Series B (Statistical Methodology), 61(3), 611-622. via the score and score_samples methods.) -->\n<!-- * FastICA (A. Hyvarinen and E. Oja, Independent Component Analysis: Algorithms and Applications, Neural Networks, 13(4-5), 2000, pp. 411-430.) -->","metadata":{}},{"cell_type":"code","source":"import numpy as np\nfrom sklearn.model_selection import train_test_split\n\nidxs = np.arange(X.shape[0])\nnp.random.shuffle(idxs)\nthresh = int((1-0.33)*len(idxs))\ntrain_idx = idxs[:thresh]\ntest_idx = idxs[thresh:]\n\nX_train, X_test, y_train, y_test = X[train_idx, :], X[test_idx, :], y[train_idx], y[test_idx]\n# DO nothing\n# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\nprint('Train test split')\n\n# Chi2\n# top_feat = 1000\n# from sklearn.feature_selection import chi2\n# bin_X_train = np.where(X_train.toarray()>0, 1, 0)\n# print('create bin')\n# chi2_val, p_value = chi2(bin_X_train, y_train)\n# top_feat_idx = np.argsort(chi2_val)[-top_feat:]\n\n# chi2X_train = X_train[:, top_feat_idx]\n# chi2X_test = X_test[:, top_feat_idx]\n# print('Chi2')\n\n# TruncatedSVD\nfrom sklearn.decomposition import TruncatedSVD\ntop_feat = 500\nsvd = TruncatedSVD(n_components=top_feat, n_iter=1, random_state=42)\nsvd.fit(X_train)\nsvdX_train = svd.transform(X_train)\nsvdX_test = svd.transform(X_test)\nprint('TruncatedSVD')\n\n# MiniBatchSparsePCA\n# from sklearn.decomposition import PCA\n\n# top_feat = 1000\n# pca = PCA(n_components=top_feat, random_state=42)\n# pca.fit(X_train.toarray())\n# pcaX_train = pca.transform(X_train.toarray())\n# pcaX_test = pca.transform(X_test.toarray())\n# print('PCA')\n\n# FastICA\n# from sklearn.decomposition import FastICA\n\n# top_feat = 1000\n# pca = FastICA(n_components=top_feat, random_state=42, max_iter=10)\n# pcaX_train = pca.fit_transform(X_train.toarray())\n# pcaX_test = pca.transform(X_test.toarray())\n# print('FastICA')\n\nX_aisle_only_train, X_aisle_only_test = X_aisle_only[train_idx, :], X_aisle_only[test_idx, :]","metadata":{"execution":{"iopub.status.busy":"2023-04-27T10:04:20.381376Z","iopub.execute_input":"2023-04-27T10:04:20.381918Z","iopub.status.idle":"2023-04-27T10:04:31.698720Z","shell.execute_reply.started":"2023-04-27T10:04:20.381868Z","shell.execute_reply":"2023-04-27T10:04:31.697294Z"},"trusted":true},"execution_count":18,"outputs":[{"name":"stdout","text":"Train test split\nTruncatedSVD\n","output_type":"stream"}]},{"cell_type":"code","source":"X.shape, X_aisle_only.shape, svdX_train.shape, X_aisle_only_train.shape\n","metadata":{"execution":{"iopub.status.busy":"2023-04-27T10:04:31.700278Z","iopub.execute_input":"2023-04-27T10:04:31.701687Z","iopub.status.idle":"2023-04-27T10:04:31.711291Z","shell.execute_reply.started":"2023-04-27T10:04:31.701630Z","shell.execute_reply":"2023-04-27T10:04:31.709839Z"},"trusted":true},"execution_count":19,"outputs":[{"execution_count":19,"output_type":"execute_result","data":{"text/plain":"((35000, 49822), (35000, 134), (23449, 500), (23449, 134))"},"metadata":{}}]},{"cell_type":"code","source":"preprocess = [\n#     ('do-nothing', X_train, X_test, y_train, y_test),\n#     ('chi2-top1000', chi2X_train, chi2X_test, y_train, y_test),\n    ('svd-500', svdX_train, svdX_test, y_train, y_test),\n    ('aisle_only', X_aisle_only_train, X_aisle_only_test, y_train, y_test)\n#     ('FastICA-1000', pcaX_train, pcaX_test, y_train, y_test),\n#     ('pca-1000', pcaX_train, pcaX_test, y_train, y_test),\n]","metadata":{"execution":{"iopub.status.busy":"2023-04-27T10:04:31.712398Z","iopub.execute_input":"2023-04-27T10:04:31.712833Z","iopub.status.idle":"2023-04-27T10:04:31.721928Z","shell.execute_reply.started":"2023-04-27T10:04:31.712790Z","shell.execute_reply":"2023-04-27T10:04:31.719988Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"markdown","source":"## CLF models\n* MLP\n* RF\n* DTree\n* LR","metadata":{}},{"cell_type":"code","source":"from lightgbm import LGBMClassifier\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.neural_network import MLPClassifier\nfrom sklearn.linear_model import LogisticRegression\n\nclfs = [\n    ('lightgbm', LGBMClassifier()),\n        ('dtree', DecisionTreeClassifier()),\n        ('rf', RandomForestClassifier(10)),\n        ('mlp', MLPClassifier()),\n        ('logreg', LogisticRegression())\n]","metadata":{"execution":{"iopub.status.busy":"2023-04-27T10:04:31.723983Z","iopub.execute_input":"2023-04-27T10:04:31.724772Z","iopub.status.idle":"2023-04-27T10:04:34.403845Z","shell.execute_reply.started":"2023-04-27T10:04:31.724688Z","shell.execute_reply":"2023-04-27T10:04:34.402496Z"},"trusted":true},"execution_count":21,"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<style type='text/css'>\n.datatable table.frame { margin-bottom: 0; }\n.datatable table.frame thead { border-bottom: none; }\n.datatable table.frame tr.coltypes td {  color: #FFFFFF;  line-height: 6px;  padding: 0 0.5em;}\n.datatable .bool    { background: #DDDD99; }\n.datatable .object  { background: #565656; }\n.datatable .int     { background: #5D9E5D; }\n.datatable .float   { background: #4040CC; }\n.datatable .str     { background: #CC4040; }\n.datatable .time    { background: #40CC40; }\n.datatable .row_index {  background: var(--jp-border-color3);  border-right: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  font-size: 9px;}\n.datatable .frame tbody td { text-align: left; }\n.datatable .frame tr.coltypes .row_index {  background: var(--jp-border-color0);}\n.datatable th:nth-child(2) { padding-left: 12px; }\n.datatable .hellipsis {  color: var(--jp-cell-editor-border-color);}\n.datatable .vellipsis {  background: var(--jp-layout-color0);  color: var(--jp-cell-editor-border-color);}\n.datatable .na {  color: var(--jp-cell-editor-border-color);  font-size: 80%;}\n.datatable .sp {  opacity: 0.25;}\n.datatable .footer { font-size: 9px; }\n.datatable .frame_dimensions {  background: var(--jp-border-color3);  border-top: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  display: inline-block;  opacity: 0.6;  padding: 1px 10px 1px 5px;}\n</style>\n"},"metadata":{}}]},{"cell_type":"code","source":"import numpy as np\n\ndef top_k_accuracy(y_pred, y_true, k):\n    # Get the top k predicted labels for each example\n    top_10_labels = np.argsort(y_pred, axis=1)[:, -k:]\n\n    # Check if the true label is in the top k predicted labels for each example\n    is_in_top_k = np.any(top_10_labels == y_true.reshape(-1, 1), axis=1)\n\n    # Calculate the top k accuracy\n    top_k_acc = np.mean(is_in_top_k)\n\n    return top_k_acc\n","metadata":{"execution":{"iopub.status.busy":"2023-04-27T10:04:34.405418Z","iopub.execute_input":"2023-04-27T10:04:34.406759Z","iopub.status.idle":"2023-04-27T10:04:34.415475Z","shell.execute_reply.started":"2023-04-27T10:04:34.406674Z","shell.execute_reply":"2023-04-27T10:04:34.413767Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"from tqdm.notebook import tqdm\nimport pandas as pd\n\nprocess = tqdm(desc='Testing....', total=len(preprocess)*len(clfs))\n\nbench_results = []\nfor (preprocess_name, x_train, x_test, y_train, y_test) in preprocess:\n    for idx, (model_name, clf) in enumerate(clfs):\n        clf.fit(x_train.astype(np.float32), y_train)\n        probs = clf.predict_proba(x_test.astype(np.float32))\n        acc = {f'acc@{k}': top_k_accuracy(probs, np.array(y_test), k) for k in [5,10,15,20]}\n        rs = {\n            'preprocessing': preprocess_name,\n            'clf': model_name,\n            **acc\n        }\n        bench_results.append(rs)\n        process.update(1)\n        \nbench_results = pd.DataFrame(bench_results)\nbench_results","metadata":{"execution":{"iopub.status.busy":"2023-04-27T10:04:34.417326Z","iopub.execute_input":"2023-04-27T10:04:34.417807Z","iopub.status.idle":"2023-04-27T10:17:31.032916Z","shell.execute_reply.started":"2023-04-27T10:04:34.417763Z","shell.execute_reply":"2023-04-27T10:17:31.031550Z"},"trusted":true},"execution_count":23,"outputs":[{"output_type":"display_data","data":{"text/plain":"Testing....:   0%|          | 0/10 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6a8b46053e5a41d4a02dfecff329b0bb"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n  ConvergenceWarning,\n/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\nSTOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n\nIncrease the number of iterations (max_iter) or scale the data as shown in:\n    https://scikit-learn.org/stable/modules/preprocessing.html\nPlease also refer to the documentation for alternative solver options:\n    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n/opt/conda/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n  ConvergenceWarning,\n/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\nSTOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n\nIncrease the number of iterations (max_iter) or scale the data as shown in:\n    https://scikit-learn.org/stable/modules/preprocessing.html\nPlease also refer to the documentation for alternative solver options:\n    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n","output_type":"stream"},{"execution_count":23,"output_type":"execute_result","data":{"text/plain":"  preprocessing       clf     acc@5    acc@10    acc@15    acc@20\n0       svd-500  lightgbm  0.078608  0.095230  0.124578  0.161285\n1       svd-500     dtree  0.060687  0.076357  0.106657  0.134707\n2       svd-500        rf  0.149771  0.227686  0.244741  0.270799\n3       svd-500       mlp  0.232015  0.334343  0.416414  0.484374\n4       svd-500    logreg  0.315211  0.431911  0.521167  0.589906\n5    aisle_only  lightgbm  0.063631  0.079907  0.111159  0.131417\n6    aisle_only     dtree  0.085447  0.101290  0.131331  0.158688\n7    aisle_only        rf  0.203532  0.273569  0.291057  0.317895\n8    aisle_only       mlp  0.287940  0.398580  0.481170  0.555450\n9    aisle_only    logreg  0.342395  0.461172  0.545061  0.614233","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>preprocessing</th>\n      <th>clf</th>\n      <th>acc@5</th>\n      <th>acc@10</th>\n      <th>acc@15</th>\n      <th>acc@20</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>svd-500</td>\n      <td>lightgbm</td>\n      <td>0.078608</td>\n      <td>0.095230</td>\n      <td>0.124578</td>\n      <td>0.161285</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>svd-500</td>\n      <td>dtree</td>\n      <td>0.060687</td>\n      <td>0.076357</td>\n      <td>0.106657</td>\n      <td>0.134707</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>svd-500</td>\n      <td>rf</td>\n      <td>0.149771</td>\n      <td>0.227686</td>\n      <td>0.244741</td>\n      <td>0.270799</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>svd-500</td>\n      <td>mlp</td>\n      <td>0.232015</td>\n      <td>0.334343</td>\n      <td>0.416414</td>\n      <td>0.484374</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>svd-500</td>\n      <td>logreg</td>\n      <td>0.315211</td>\n      <td>0.431911</td>\n      <td>0.521167</td>\n      <td>0.589906</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>aisle_only</td>\n      <td>lightgbm</td>\n      <td>0.063631</td>\n      <td>0.079907</td>\n      <td>0.111159</td>\n      <td>0.131417</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>aisle_only</td>\n      <td>dtree</td>\n      <td>0.085447</td>\n      <td>0.101290</td>\n      <td>0.131331</td>\n      <td>0.158688</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>aisle_only</td>\n      <td>rf</td>\n      <td>0.203532</td>\n      <td>0.273569</td>\n      <td>0.291057</td>\n      <td>0.317895</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>aisle_only</td>\n      <td>mlp</td>\n      <td>0.287940</td>\n      <td>0.398580</td>\n      <td>0.481170</td>\n      <td>0.555450</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>aisle_only</td>\n      <td>logreg</td>\n      <td>0.342395</td>\n      <td>0.461172</td>\n      <td>0.545061</td>\n      <td>0.614233</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\n\n\nclass DeepModelWrapper:\n    \n    def predict_proba(self, test_x, batch_size=256):\n        pred = self.predict(\n            test_x,\n            batch_size=batch_size,\n        )\n        return pred\n\nclass NeuralDecisionTree(keras.Model, DeepModelWrapper):\n    def __init__(self, depth, num_features, used_features_rate, num_classes):\n        super().__init__()\n        self.depth = depth\n        self.num_leaves = 2 ** depth\n        self.num_classes = num_classes\n\n        # Create a mask for the randomly selected features.\n        num_used_features = int(num_features * used_features_rate)\n        one_hot = np.eye(num_features)\n        sampled_feature_indicies = np.random.choice(\n            np.arange(num_features), num_used_features, replace=False\n        )\n        self.used_features_mask = one_hot[sampled_feature_indicies]\n\n        # Initialize the weights of the classes in leaves.\n        self.pi = tf.Variable(\n            initial_value=tf.random_normal_initializer()(\n                shape=[self.num_leaves, self.num_classes]\n            ),\n            dtype=\"float32\",\n            trainable=True,\n        )\n\n        # Initialize the stochastic routing layer.\n        self.decision_fn = layers.Dense(\n            units=self.num_leaves, activation=\"sigmoid\", name=\"decision\"\n        )\n\n    def call(self, features):\n        batch_size = tf.shape(features)[0]\n\n        # Apply the feature mask to the input features.\n        features = tf.matmul(\n            features, self.used_features_mask, transpose_b=True\n        )  # [batch_size, num_used_features]\n        # Compute the routing probabilities.\n        decisions = tf.expand_dims(\n            self.decision_fn(features), axis=2\n        )  # [batch_size, num_leaves, 1]\n        # Concatenate the routing probabilities with their complements.\n        decisions = layers.concatenate(\n            [decisions, 1 - decisions], axis=2\n        )  # [batch_size, num_leaves, 2]\n\n        mu = tf.ones([batch_size, 1, 1])\n\n        begin_idx = 1\n        end_idx = 2\n        # Traverse the tree in breadth-first order.\n        for level in range(self.depth):\n            mu = tf.reshape(mu, [batch_size, -1, 1])  # [batch_size, 2 ** level, 1]\n            mu = tf.tile(mu, (1, 1, 2))  # [batch_size, 2 ** level, 2]\n            level_decisions = decisions[\n                :, begin_idx:end_idx, :\n            ]  # [batch_size, 2 ** level, 2]\n            mu = mu * level_decisions  # [batch_size, 2**level, 2]\n            begin_idx = end_idx\n            end_idx = begin_idx + 2 ** (level + 1)\n\n        mu = tf.reshape(mu, [batch_size, self.num_leaves])  # [batch_size, num_leaves]\n        probabilities = keras.activations.softmax(self.pi)  # [num_leaves, num_classes]\n        outputs = tf.matmul(mu, probabilities)  # [batch_size, num_classes]\n        return outputs\n    \nclass NeuralDecisionForest(keras.Model, DeepModelWrapper):\n    def __init__(self, num_trees, depth, num_features, used_features_rate, num_classes):\n        super().__init__()\n        self.ensemble = []\n        # Initialize the ensemble by adding NeuralDecisionTree instances.\n        # Each tree will have its own randomly selected input features to use.\n        for _ in range(num_trees):\n            self.ensemble.append(\n                NeuralDecisionTree(depth, num_features, used_features_rate, num_classes)\n            )\n        self.num_classes = num_classes\n\n    def call(self, inputs):\n        # Initialize the outputs: a [batch_size, num_classes] matrix of zeros.\n        batch_size = tf.shape(inputs)[0]\n        outputs = tf.zeros([batch_size, self.num_classes])\n\n        # Aggregate the outputs of trees in the ensemble.\n        for tree in self.ensemble:\n            outputs += tree(inputs)\n        # Divide the outputs by the ensemble size to get the average.\n        outputs /= len(self.ensemble)\n        return outputs","metadata":{"execution":{"iopub.status.busy":"2023-04-27T10:17:31.038628Z","iopub.execute_input":"2023-04-27T10:17:31.039761Z","iopub.status.idle":"2023-04-27T10:17:42.377690Z","shell.execute_reply.started":"2023-04-27T10:17:31.039680Z","shell.execute_reply":"2023-04-27T10:17:42.375605Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\n\nbench_results = []\nprocess = tqdm(desc='Testing....', total=len(preprocess))\nfor (preprocess_name, x_train, x_test, y_train, y_test) in preprocess:\n    clf = NeuralDecisionForest(num_trees=20, \n                     depth=5, \n                     num_features = x_train.shape[-1], \n                     used_features_rate= 0.5, \n                     num_classes=num_aisle)\n    clf.build(input_shape=x_train.shape)\n    clf.compile(\n        optimizer=keras.optimizers.Adam(learning_rate=0.01),\n        loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n    )\n\n    clf.fit(x_train, y_train, epochs=10, batch_size=164)\n    probs = clf.predict_proba(x_test.astype(np.float32))\n    acc = {f'acc@{k}': top_k_accuracy(probs, np.array(y_test), k) for k in [5,10,15,20]}\n    rs = {\n        'preprocessing': preprocess_name,\n        'clf': 'NeuralDecisionForest',\n        **acc\n    }\n    bench_results.append(rs)\n    process.update(1)\n","metadata":{"execution":{"iopub.status.busy":"2023-04-27T10:17:42.380710Z","iopub.execute_input":"2023-04-27T10:17:42.382217Z","iopub.status.idle":"2023-04-27T10:21:16.951643Z","shell.execute_reply.started":"2023-04-27T10:17:42.382161Z","shell.execute_reply":"2023-04-27T10:21:16.950235Z"},"trusted":true},"execution_count":25,"outputs":[{"output_type":"display_data","data":{"text/plain":"Testing....:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3d6a30845e8d4893aba520a2630b670f"}},"metadata":{}},{"name":"stdout","text":"Epoch 1/10\n143/143 [==============================] - 26s 53ms/step - loss: 4.5092\nEpoch 2/10\n143/143 [==============================] - 7s 52ms/step - loss: 4.1782\nEpoch 3/10\n143/143 [==============================] - 8s 53ms/step - loss: 4.0833\nEpoch 4/10\n143/143 [==============================] - 8s 54ms/step - loss: 4.0132\nEpoch 5/10\n143/143 [==============================] - 8s 54ms/step - loss: 3.9537\nEpoch 6/10\n143/143 [==============================] - 8s 54ms/step - loss: 3.8960\nEpoch 7/10\n143/143 [==============================] - 8s 56ms/step - loss: 3.8370\nEpoch 8/10\n143/143 [==============================] - 8s 55ms/step - loss: 3.7757\nEpoch 9/10\n143/143 [==============================] - 8s 55ms/step - loss: 3.7132\nEpoch 10/10\n143/143 [==============================] - 8s 55ms/step - loss: 3.6520\n46/46 [==============================] - 4s 40ms/step\nEpoch 1/10\n143/143 [==============================] - 26s 45ms/step - loss: 4.5004\nEpoch 2/10\n143/143 [==============================] - 6s 45ms/step - loss: 4.2252\nEpoch 3/10\n143/143 [==============================] - 6s 45ms/step - loss: 4.1737\nEpoch 4/10\n143/143 [==============================] - 6s 44ms/step - loss: 4.1381\nEpoch 5/10\n143/143 [==============================] - 6s 43ms/step - loss: 4.1015\nEpoch 6/10\n143/143 [==============================] - 6s 42ms/step - loss: 4.0685\nEpoch 7/10\n143/143 [==============================] - 6s 42ms/step - loss: 4.0341\nEpoch 8/10\n143/143 [==============================] - 6s 41ms/step - loss: 3.9962\nEpoch 9/10\n143/143 [==============================] - 6s 42ms/step - loss: 3.9626\nEpoch 10/10\n143/143 [==============================] - 6s 42ms/step - loss: 3.9357\n46/46 [==============================] - 3s 14ms/step\n","output_type":"stream"}]},{"cell_type":"code","source":"bench_results = pd.DataFrame(bench_results)\nbench_results","metadata":{"execution":{"iopub.status.busy":"2023-04-27T10:21:16.953255Z","iopub.execute_input":"2023-04-27T10:21:16.953700Z","iopub.status.idle":"2023-04-27T10:21:16.973945Z","shell.execute_reply.started":"2023-04-27T10:21:16.953658Z","shell.execute_reply":"2023-04-27T10:21:16.972516Z"},"trusted":true},"execution_count":26,"outputs":[{"execution_count":26,"output_type":"execute_result","data":{"text/plain":"  preprocessing                   clf     acc@5    acc@10    acc@15    acc@20\n0       svd-500  NeuralDecisionForest  0.301619  0.410181  0.492511  0.560904\n1    aisle_only  NeuralDecisionForest  0.320145  0.426457  0.506190  0.572158","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>preprocessing</th>\n      <th>clf</th>\n      <th>acc@5</th>\n      <th>acc@10</th>\n      <th>acc@15</th>\n      <th>acc@20</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>svd-500</td>\n      <td>NeuralDecisionForest</td>\n      <td>0.301619</td>\n      <td>0.410181</td>\n      <td>0.492511</td>\n      <td>0.560904</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>aisle_only</td>\n      <td>NeuralDecisionForest</td>\n      <td>0.320145</td>\n      <td>0.426457</td>\n      <td>0.506190</td>\n      <td>0.572158</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]}]}